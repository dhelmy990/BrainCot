Analyse & Kritik 26/2004 ( c© Lucius & Lucius, Stuttgart) p. 382–397Andrew Brook/Pete MandikThe Philosophy and Neuroscience Movement∗Abstract: A movement dedicated to applying neuroscience to traditional philosoph-ical problems and using philosophical methods to illuminate issues in neurosciencebegan about twenty-five years ago. Results in neuroscience have affected how we seetraditional areas of philosophical concern such as perception, belief-formation, and con-sciousness. There is an interesting interaction between some of the distinctive featuresof neuroscience and important general issues in the philosophy of science. And recentneuroscience has thrown up a few conceptual issues that philosophers are perhaps besttrained to deal with. After sketching the history of the movement, we explore therelationships between neuroscience and philosophy and introduce some of the specificissues that have arisen.0. IntroductionThe exponentially-growing body of work on the human brain of the past fewdecades has not only taught us a lot about how the brain does cognition, ithas also had a profound influence on other disciplines that study cognition andbehaviour. A notable example, interestingly enough, is philosophy. A smallmovement dedicated to applying neuroscience to traditional philosophical prob-lems and using philosophical methods to illuminate issues in neuroscience beganabout twenty-five years ago and has been gaining momentum ever since. Thecentral thought behind it is that certain basic questions about human cognition,questions that have been studied in many cases for millennia, will be answeredonly by a philosophically sophisticated grasp of what contemporary neuroscienceis teaching us about how the human brain processes information.The evidence for this proposition is now overwhelming. The philosophicalproblem of perception has been transformed by new knowledge about the vi-sion systems in the brain. Our understanding of memory has been deepened byknowing that two quite different systems in the brain are involved in short- andlong-term memory. Knowing something about how language is implemented inthe brain has transformed our understanding of the structure of language, espe-cially the structure of many breakdowns in language. And so on. On the otherhand, a great deal is still unclear about the implications of this new knowledgeof the brain. Are cognitive functions localized in the brain in the way assumed∗ This paper draws upon material in Andrew Brook/Pete Mandik, ‘Introduction’, AndrewBrook/Kathleen Akins (eds.), Cognition and the Brain: The Philosophy and NeuroscienceMovement, pp. 1–27. c© Cambridge University Press 2005, reproduced with permission.The Philosophy and Neuroscience Movement 383by most recent work on brain imaging? Does it even make sense to think ofcognitive activity being localized in such a way? Does knowing about the areasactive in the brain when we are conscious of something hold any promise forhelping with long-standing puzzles about the nature and role of consciousness?And so on.As a result of this interest, a group of philosophers and neuroscientists dedi-cated to informing each other’s work has grown up. Many of these people nowhave Ph.D.-level training or the equivalent in both neuroscience and philosophy.Much of the work that has appeared has been clustered around five themes,• data and theory in neuroscience• neural representation and computation• visuomotor transformation• colour vision• consciousnessand two big issues lie in the substructure of all of them,• the relationship of neuroscience to the philosophy of science,and,• whether cognitive science will be reduced to neuroscience or eliminated byit.We will take up these themes shortly. But first, a sketch of some relevant history.1. History of Research Connecting Philosophy and Neuro-sciencePrior to the 1980’s, very little philosophical work drew seriously on scientificwork concerning the nervous system or vice-versa. Descartes speculated in (1649)that the pineal gland constituted the interface between the un-extended mindand the extended body and did some anatomy in laboratories (including on live,not anaesthetized animals; in his view, animals do not have the capacity to feelpain) but he is at most a modest exception.Coming to the 20th century, even when the idea that the mind is simply thebrain was promoted in the mid twentieth century by the identity theorists, akacentral state materialists, they drew upon very little actual brain science. In-stead, the philosophy was speculative, even somewhat fanciful. Some examples.Herbert Feigl (1958/1967) proposed an autocerebroscope whereby people coulddirectly observe their own mental/neural processes. This was science fiction, notscience fact or even realistic scientific speculation. Much discussion of identitytheory involved the question of the identification of pain with C-fibre firings (U.384 Andrew Brook/Pete MandikT. Place 1956 and J. C. Smart 1959). But it has been known for a very long timethat the neural basis of pain is much more complicated than that (see Hardcastle1997 for a recent review).There were a few exceptions to the general ignorance about neuroscienceamong philosophers prior to the 1980s. Thomas Nagel (1971) is an example. Inthis paper, he discusses the implications of experiments with commissurotomy(brain bisection) patients for the unity of consciousness and the person. Dennett(1978) discusses the question of whether a computer could be built that felt painand did a thorough and still interesting summary of what was known about painneurophysiology at the time. Barbara Von Eckardt-Klein (1975) discussed theidentity theory of sensations in terms of then-current work on neural codingby Mountcastle, Libet, and Jasper. But these exceptions were very much theexception.The failure of philosophers of the era to draw on actual neuroscientific workconcerning psychoneural identities could not be blamed on any lack of relevantwork in neuroscience. David Hubel and Torsten Wiesel’s (1962) Nobel-prize-winning work on the receptive fields of visual neurons held great promise forthe identification of various visual properties with various neural processes. Adecade earlier, Donald Hebb (1949) had tried to explain cognitive phenomenasuch as perception, learning, memory, and emotional disorders in terms of neuralmechanisms.In the 1960s, the term ‘neuroscience’ emerged as a label for the interdisci-plinary study of nervous systems. The Society for Neuroscience was foundedin 1970. (It now has more than 25,000 members.) In the mid-1970s, the term‘cognitive science’ was adopted as the label for interdisciplinary studies of cog-nition and the idea took hold that what we mean by ‘mind’ is primarily a set offunctions for processing information. The idea of information processing mightnot have been much more than a uniting metaphor without the advent of large-capacity computers. For over three decades now, real effort has been put intoimplementing the relevant functions in computational systems (this is one lead-ing kind of artificial intelligence). Cognitive Science became institutionalizedwith the creation of the Cognitive Science Society and the journal CognitiveScience in the late 1970s. However, it has not grown the way neuroscience has.After thirty years, the Cognitive Science Society has about 2000 members.Until the 1980s, there was very little interaction between neuroscience andcognitive science. On the philosophical front, this lack of interaction was prin-cipled (if wrong-headed). It was based on a claim, owing to functionalists suchas Jerry Fodor (1974) and Hilary Putnam (1967), that, since cognition couldbe multiply realized in many different neural as well as non-neural substrates,nothing essential to cognition could be learned by studying neural (or any other)implementation. It is the cognitive functions that matter, not how they are im-plemented in this, that, or the other bit of silicon or goopy wetware.The 1980s witnessed a rebellion against this piece of dogma. Partly this wasbecause of the development of new and much more powerful tools for studyingbrain activity, fMRI (functional magnetic resonance imaging; the ‘f’ is usuallylower-case for some reason) brain scans in particular. In the sciences, psycholo-The Philosophy and Neuroscience Movement 385gist George Miller and neurobiologist Michael Gazzaniga coined the term ‘cogni-tive neuroscience’ for the study of brain implementation of cognitive functioning.Cognitive neuroscience studies cognition in the brain through techniques suchas PET (positron emission tomography) and fMRI that allow us to see how be-haviour and cognition, as studied by cognitive scientists, is expressed in functionsin the brain, as studied by neuroscientists. The idea of relating cognitive pro-cesses to neurophysiological processes was not invented in the 1980s, however.For example, in the 1970s, Eric Kandel (1976) proposed explaining simple formsof associative learning in terms of presynaptic mechanisms governing transmitterrelease. Bliss and Lomo (1973) related memory to the cellular mechanisms oflong term potentiation (LTP).In philosophy, an assault on the functionalist separation of brain and mindwas launched with the publication of Patricia (P. S.) Churchland’s Neurophilos-ophy in 1986 (a book still in print and widely read). Churchland’s book hasthree main aims:1. to develop an account of intertheoretic reduction and specifically of thereduction of mind to brain radically different from the one in logical posi-tivist philosophy of science;2. to show that consciousness-based objections to psychoneural reduction donot work,and,3. to show that functionalist/multiple realizability objections to psychoneuralreduction do not work.A later neurophilosophical rebellion against multiple realizability was Bechteland Mundale (1997). Their argument was based on the way in which neurosci-entists use psychological criteria in determining what counts as a brain area.With this sketch of the history of how the philosophy and neuroscience move-ment emerged, let us now look at some particular topic areas. We will saysomething about the relevant history of each area and examine briefly what isgoing on currently. By and large, the topics of primary interest in the philoso-phy of neuroscience are topics that tie the issue of the relationship of the mind(cognition) to the brain into current philosophy of science.Indeed, it is not always easy to distinguish philosophy of mind from philos-ophy of science in the philosophy and neuroscience movement. For example,the philosophy of mind question, ‘are cognitive processes brain processes?’, isclosely related to the philosophy of science question ‘are psychological theoriesreducible to neurophysiological theories?’ Either way, neurophilosophical inter-est is mostly concerned with research on the brain that is relevant to the mind(Gold/Stoljar 1999, explore the relationship of neuroscience and the cognitivesciences in detail). There are a few exceptions. An important philosophicalstudy of areas of neuroscience not directly relevant to cognition is Machamer etal. (2000), who discuss individual neurons, how neurons work, and so on. Butthat is the general pattern.386 Andrew Brook/Pete MandikWe now turn to the big background issues identified earlier, namely, neu-roscience and the philosophy of science; and reductionism vs eliminativism inneuroscience and cognitive science.2. Neuroscience and the Philosophy of ScienceIn much early philosophy of science, the notion of law is central, as in theDeductive-Nomological theory of scientific explanation or the Hypothetico-Deductive theory of scientific theory development or discussions of intertheoreticreduction. While the nomological view of science seems entirely applicable tosciences such as physics, there is a real question as to whether it is appropriatefor life sciences such as biology and neuroscience. One challenge is based onthe seeming teleological character of biological systems. Mundale and Bechtel(1996) argue that a teleological approach can integrate neuroscience, psychologyand biology.Another challenge to the hegemony of nomological explanation comes fromphilosophers of neuroscience who argue that explanations in terms of laws atthe very least need to be supplemented by explanations in terms of mechanisms(Bechtel/Richardson 1993; Bechtel 2007; Machamer/Craver 2000; Craver 2007).Here is how their story goes. Nomological explanations, as conceived by theDeductive-Nomological model, involve showing that a description of the targetphenomenon is logically deducible from a statement of general law. Advocatesof the mechanistic model of explanation claim that adequate explanations ofcertain target phenomena can be given by describing how the phenomena resultsfrom various processes and sub-processes. For example, cellular respiration isexplained by appeal to various chemical reactions and the areas in the cell wherethese reactions take place. Laws are not completely abandoned but they aresupplemented (Mandik/Bechtel 2002).One main reason why neuroscience raises issues such as these in stark formis that, while there is clearly an enormous amount of structure in the brain(the human brain is made up of roughly 100,000,000,000 neurons), neurosciencehas had very little success in finding general laws that all or nearly all brainsinstantiate. Maybe for at least the complex kinds of activity that underpincognition, it will turn out that there are no such laws, just masses and massesof individually-distinct (though still highly structured) events.A related challenge to logical positivist philosophy of science questions whetherscientific theories are best considered to be sets of sentences at all. Paul (P.M.)Churchland (1989, 2007), for example, suggests that the vector space model ofneural representation should replace the view of representations as sentences(more on vector spaces below). This would completely recast our view of theenterprise of scientific theorizing, hypothesis testing, and explanation. This chal-lenge is directly connected to the next issue.3. Reduction Versus EliminationThe Philosophy and Neuroscience Movement 387There are three general views concerning the relation between the psychologicalstates posited by cognitive science and the neurophysiological processes studiedin the neurosciences:(1) The autonomy thesis: While every psychological state may be (be imple-mented by, be supervenient on) a brain state, types of psychological states willnever be mapped onto types of brain states. Thus, each domain needs to beinvestigated by distinct means, cognitive science for cognitively-delineated typesof activity, neuroscience for activities described in terms of brain processes andstructures (Fodor 1974).Analogy: every occurrence of red is a shape of some kind, but the colour-type,redness, does not map onto any shape-type. Colours can come in all shapes andshapes can be any colour (see Brook and Stainton (2000, ch. 4) for backgroundon the issue under discussion here).(2) Reductionism: Types of psychological states will ultimately be found to betypes neurophysiological states; every cognitively-delineated type can be mappedonto some type of brain process and/or structure with nothing much left over.The history of science has been in no small part a history of such reduction, asthey are (somewhat misleadingly) called (misleading because the reduced kindsstill continue to exist): Chemistry has been shown to be a branch of physics,large parts of biology have been shown to be a branch of chemistry, and so on.Reductivists about cognition (or psychology generally) believe that cognition(and psychology generally) will turn out to be a branch of biology.(3) Eliminativism (aka eliminative materialism): Psychological theories are soriddled with error and psychological concepts are so weak when it comes tobuilding a science out of them that psychological states are best regarded astalking about nothing that actually exists.To give just one example of the kind of argument mounted in support of elimi-nativism, phenomena identified using psychological concepts are difficult if notimpossible to quantify precisely, but all successful sciences quantify the kinds ofthing of interest. Eliminativist arguments are anti-reductivist in one very im-portant way: They argue that there is no way to reduce psychological theoriesto neural theories and even if there were, there would be no point in doing so.Philosophers of neuroscience generally fall into either the reductionist or theeliminativist camps. Most are reductionists of some stripe—most, for example,take the phenomena talked about in the ‘cognitive’ part of cognitive neuro-science to be both perfectly real and perfectly well described using psychologicalconcepts—but most are also not very dogmatic about the matter. If some psy-chological concepts turn to be so confused or vague as to be useless for scienceor to carve things up in ways that do not correspond to what neuroscience dis-covers about what structures and functions in the brain are actually like, mostpeople in the philosophy and neuroscience movement would accept that theseconcepts should be eliminated; we shouldn’t even try to reduce them. Few aretotal eliminativists—even the most radical people in the philosophy and neuro-science movement accept that some of the work of cognitive science will turn388 Andrew Brook/Pete Mandikout to have enduring value. To give just one example, though it is a leadingexample, almost nobody, not even the ‘high priests’ of eliminativism, Paul andPatricia Churchland, have ever argued that the concept of consciousness shouldbe eliminated. Maybe it should be shaped up a bit, trimmed back in places, butnearly everyone holds that the concept refers to something real and important.Some philosophers of neuroscience explicitly advocate a mixture of the two.For instance, the Churchlands seem to hold that ‘folk psychology’ (our everydayways of thinking and talking about ourselves as psychological beings) will mostlybe eliminated, but many concepts of scientific psychology will be mapped onto,‘reduced’ to, concepts of neuroscience. For example, while they have held that‘folk concepts’ such as belief and desire do not name anything real, scientificpsychological concepts such as representation do (so long as we keep our notionof representation neutral with respect to the various theories of what representa-tions are). Many kinds of representation will ultimately be found to be identicalto some particular kind of neural state or process (P. S. Churchland 1986).In the space we have, we cannot go into the merits of reductivist vs. elim-inativist claims, but notice that the truth of eliminativism will rest on at leasttwo things:(1) The first concerns what the current candidates for elimination actually turnout to be like when we understand them better. For example, eliminativistsabout folk psychology often assume that folk psychology views representationsas structured something like sentences and computations over representationsto very similar to logical inference (P. M. Churchland 1981; Stich 1983; P. S.Churchland 1986). Now, there are explicit theories that representation is likethat. Fodor (1975), for example, defends the ideas that all thought is structuredin a language, a language of thought. But it is not clear that any notion of whatrepresentations are like is built into our very folk concept of representation. Thepicture of representation and computation held by most neuroscientists is verydifferent from the notion that representations are structured like sentences, as wewill see when we get to computation and representation, so if the sententialistidea were built into folk psychology, then folk psychology would probably be introuble. But it is not clear that any such idea is built into folk psychology.(2) The second thing on which the truth of eliminativism will depend is whatexactly reduction is like. This is a matter of some controversy (Hooker 1981; P.S. Churchland 1986). For example, can reductions be less than smooth, withsome bits reduced, some bits eliminated, and still count as reductions? Or whatif the theory to be reduced must first undergo some rejigging before it can bereduced? Can we expect theories dealing with units of very different size andcomplexity (as in representations in cognitive science, neurons in neuroscience)to be reduced to one another at all? And how much revision is tolerable beforereduction fails and we have outright elimination and replacement on our hands?Bickle (1998) argues for a revisionary account of reduction. McCauley (2001)argues that reductions are usually between theories at roughly the same level(intratheoretic), not between theories dealing with radically different basic units(intertheoretic).The Philosophy and Neuroscience Movement 389These big issues in the philosophy of neuroscience have been hashed andrehashed in the past twenty-five years. The burgeoning results in neurosciencehave thrown the issues up in high relief and sometimes have given them newcontent. Work on them by philosophers has helped neuroscientists develop amore precise sense of exactly how their work relates to other scientific work,cognitive science in particular. It is interesting, even a bit remarkable, that,as we noted, most people in the philosophy and neuroscience movement havearrived at roughly the same position on them. Thus, even though they form thebackground to most current work, we will say no more about them.On many more specific topics, we are far from having such a settled position.We turn now to a representative sample of these topics. We identified themearlier:• Data and theory in neuroscience.The issue of the relationship of data to theory contains a huge group of subissues.We will restrict ourselves to two issues: Can introspection generate good datafor neuroscience? And, is function in the brain localized to specific regions (oftenreferred to as modules) or spread across wide areas of the brain.• Neural representation and computation.A huge topic! Here we will focus on the architecture, syntax, and semantics ofneural representation• Visuomotor transformation.Under this heading, we will examine two issues. The first concerns the hypothesisthat we have two visual systems: one for conscious perception and the other foraction. The second concerns the increasingly popular hypothesis that perceptionand control of behaviour are interdependent.• Colour visionHere the big issue is over how to think about the relationship between colourexperiences and the distal stimuli that elicit such experiences. One thing thatis puzzling about this relationship is that the ways in which colours are experi-enced diverges quite dramatically from the ways in which their environmentaltriggers—the ostensible colours themselves—actually are.• ConsciousnessTwo pressing issues among many in connection with consciousness are the issue,first, whether consciousness is just a part of cognition or something unique and,in some measure at least, beyond the reach of either cognitive science or neuro-science forever and, second, if consciousness is cognitive, what kind of cognitiveprocess/structure is it, and if it is not, with what kind of cognitive and brainprocesses and structures is it associated?11Papers discussing all these issues in more detail can be found in Brook/Akins 2005. Forother recent anthologies of articles in the growing intersection of philosophy and neurosciencesee Bechtel et. al 2001, Keeley 2006, and Bickle (in press).390 Andrew Brook/Pete Mandik4. Data and Theory: Introspection, Localization, Modular-ity4.1 IntrospectionIn a variety of ways, the advent of sophisticated imaging of brain activity hascreated a new reliance on introspection—it is difficult if not impossible to relatewhat is going on cognitively to various brain activities without self-reports fromsubjects about what is going on in them. Introspection has been in bad odouras a research tool for over 100 years. It has variously been claimed that1. introspective claims are unreliable because they are not regularly replicatedin others.2. subjects confabulate (make up stories) about what is going on in them-selves when they need to do so to make sense of behaviour.3. introspection has access only to a tiny fraction of what is going on in oneselfcognitively.4. it is impossible for introspection to access brain states.And so on. However, researchers into the brain (neuroscience) have beenforced back onto introspection because often the only access that they have tothe cognitive and conscious functions that they want to study in the brain isthe access that the subject him or herself has. It is perhaps a bit ironic thatneuroscience, the most scientific of approaches to human nature to date, hasbeen forced to fall back onto a technique rejected as unscientific over 100 yearsago!One interesting middle position gaining some currency is that some of thelimitations in introspection can be overcome by training. After training andpractise introspection can come to be much more reliable than it is in its nativestate—perhaps even reliable enough to introspectively identify internal events interms of the taxonomy of neuroscience, and thus introspect brain states as such(Churchland 1989; Mandik 2006).Another way around the classical and classically unreliable appeal to intro-spection is to point out that not all first-person utterances are introspectivereports. Perhaps when first-person utterances are expressing feelings, for exam-ple, they are or at least can be more reliable sources of data that first-personutterances that report self-observations are. Among other things, with first per-son utterances that express rather than report, there may no longer be a conflictbetween the use of subjectively-rooted utterances and the requirement that ev-idence be public.4.2 LocalizationThe Philosophy and Neuroscience Movement 391A question with a long history in the study of the brain concerns how localizedcognitive function is. Early localization theorists (early 1800s) included thephrenologists Gall and Spurzheim. Flourens was a severe early critic of the ideafrom the same period.Localizationism re-emerged in the study of the linguistic deficits of aphasicpatients of Bouillaud, Auburtin, Broca, and Wernicke in the mid 1800s. Brocanoted a relation between speech production deficits and damage to the left cor-tical hemisphere especially in the second and third frontal convolutions. Thuswas ‘Broca’s area’ born. It is considered to be a speech production locus in thebrain. Less than two decades after Broca’s work, Wernicke linked linguistic com-prehension deficits with areas in the first and second convolutions in temporalcortex now called ‘Wernicke’s Area’.The lesion/deficit method of inferring functional localization raises severalquestions of its own, especially for functions such as language for which there areno animal models (Von Eckardt 1978). Imaging technologies help alleviate someof the problems encountered by lesion/deficit methodology (for instance, thepatient doesn’t need to die before the data can be collected!). We mentioned twoprominent imaging techniques earlier: positron emission tomography, or PET,and functional magnetic resonance imaging, or fMRI. Both have limitations,however. The best spatial resolution they can achieve is around 1mm. A lot ofneurons can reside in a 1mm by 1mm space! And there are real limitations onhow short a time-span they can measure, though these latter limitations varyfrom area to area and function to function. However, resolution improves everyyear, especially in fMRI.In PET, radionuclides possessing excessive protons are used to label water orsugar molecules that are then injected into the patient’s blood stream. Detectorsarranged around the patient’s head detect particles emitted in the process of theradioactive decay of the injected nuclides. PET thus allows the identification ofareas high in blood flow and glucose utilization, which is believed to be correlatedwith level of neural and glial cell activity (a crucial and largely untested, maybeuntestable, assumption). PET has been used to obtain evidence of activity inanterior cingulate cortex correlated with the executive control of attention, forexample, and to measure activity in neural areas during linguistic tasks likereading and writing (Caplan/Carr/Gould/Martin 1999). For a philosophicaltreatment of issues concerning PET, see Stuﬄebeam and Bechtel (1997).fMRI measures amount of oxygenation or phosphorylation in specific regionsof neural tissue. Amounts of cell respiration and cell ATP utilization are taken toindicate amount of neural activity. fMRI has been used to study the localizationof linguistic functions, memory, executive and planning functions, consciousness,memory, and many, many other cognitive functions. Bechtel and Richardson(1993) and Bechtel and Mundale (1997) discuss some of the philosophical issuesto do with localization.However much MRI may assume and depend on the idea that cognitive func-tion is localized in the brain, the idea faces grave difficulties. Even a systemas simple and biologically basic as oculomotor control (the control system thatkeeps the eyes pointed in one direction as the head moves around, for example)392 Andrew Brook/Pete Mandikis the very reverse of localized. Units dispersed widely across cortex contributeto performing this function. Moreover, many of these units are also involvedin many other information-processing and control activities. A further factorpointing in the same anti-localization direction is that the brain is very plastic,especially in childhood. If one area is damaged, often another area can take overthe functions previously performed by the damaged area. (Since these claimsarise from actually observing how the brain does things, they also underminethe old idea that we can study cognitive function without studying the brain.)4.3 ModularityThe question of localization connects to the question of modularity, another bigissue in cognitive neuroscience. Fodor (1983) advanced a strong modularity the-sis concerning the cognitive architecture of peripheral systems (vision, language,touch, and the like). According to Fodor, a module is defined in terms of thefollowing properties (1) domain specificity, (2) mandatory operation, (3) lim-ited output to central processing, (4) rapidity, (5) information encapsulation,(6) shallow outputs, (7) fixed neural architecture, (8) characteristic and specificbreakdown patterns, and (9) characteristic pace and sequencing of development.Fodor then argued that most of the brain’s peripheral systems are modular,sometimes multi-modular, while the big central system in which the thinking,remembering, and so on is done, is emphatically not.Fodor’s account can be resisted in two ways. One is to argue that he hasan overly restricted notion of what a module has to be like. The other is toargue that, no matter how characterized, there are precious few if any modulesin the brain. The latter is what the work sketched two paragraphs ago wouldsuggest. Another body of evidence supporting the same conclusion concernsback projection. Temporal cortical areas implicated in high levels of visualprocessing, for example, send back projections to lower level areas in primaryvisual cortex which in turn send back projections to even lower areas in the lateralgeniculate nuclei and ultimately back to the retina. Applebaum (1998) argues forsimilar phenomena in speech perception: higher-level lexical processing affectslower-level phonetic processing. In fact, neuroscientific research shows that backprojections are to be found everywhere. But where there are back projections,there cannot be encapsulated modules.5. Neural Representation and ComputationNeural representation and computation is a huge topic, as we said. We will startwith neural representation.The neurophilosophical questions concerning computation and representationnearly all assume a definition of computation in terms of transformation of rep-resentations. Thus, most questions concerning computation and representationare really questions about representation. Contributions to this topic can beThe Philosophy and Neuroscience Movement 393thought of as falling into three groups, though the boundaries between them arefar from crisp. There are questions to do with architecture, question to do withsyntax, and questions to do with semantics. The question of architecture is thequestion of how a neural system having syntax and semantics might be struc-tured. The question of syntax is the question of what the formats or permissibleformats of the representations in such a system might be and how representationsinteract with each other based on their form alone. The questions of semanticsis the question of how it is that such representations come to represent—howthey come to have content, meaning.5.1 Architecture of Neural RepresentationHere is some of the thinking afoot currently about neural architecture. Past ap-proaches to understanding the mind, including symbolicism, connectionism, anddynamicism, rely heavily on metaphors. A much less metaphorical approach,or so it is claimed, unifies representational and dynamical descriptions of themind. First, representation is rigorously defined by encoding and decoding rela-tions. Then, the variables identified at higher levels are treated as state variablesin control theoretical descriptions of neural dynamics. Given the generality ofcontrol theory and representation so defined, it is claimed that this approach issufficiently powerful to unify descriptions of cognitive systems from the neuralto the psychological levels. If so, contrary to dynamicist arguments (van Gelder1998), one can have both representation and dynamics in cognitive science.5.2 Neural syntaxThe standard way of interpreting synaptic events and neural activity patterns asrepresentations is to see them as constituting points and trajectories in vectorspaces. The computations that operate on these representations will then beseen as vector transformations (P. M. Churchland 1989). This is thus the viewadopted in much neural network modelling (connectionism, parallel distributedprocessing). The system is construed as having network nodes (neurons) as itsbasic elements and representations are states of activations in sets of one or moreneurons. (Bechtel/Abrahamsen 2002; Clark 1993).Recently, work in neural modelling has started to become even more fine-grained. This new work does not treat the neuron as the basic computationalunit, but instead models activity in and interactions between patches of the neu-ron’s membrane (Bower/Beeman 1995). Thus, not only are networks of neuronsviewed as performing vector transformations, but so are individual neurons.Neural syntax consists of the study of the information-processing relation-ships among neural units, whatever one takes the relevant unit to be. Anyworked-out story about the architecture of neural representation will hold impli-cations for neural syntax, for what kind of relationships neural representations394 Andrew Brook/Pete Mandikwill have to other neural representations such that they can be combined andtransformed computationally.5.3 Neural semanticsCognitive science and cognitive neuroscience are guided by the vision ofinformation-processing systems. A crucial component of this vision is that statesof the system carry information about or represent aspects of the external world(see Newell 1980). Thus, a central role is posited for intentionality, a represen-tation being about something, mirroring Franz Brentano’s (1874) insistence onits importance a century before (he called it ‘the mark of the mental’, only aslight exaggeration).How do neural states come to have contents? There are three broad answersto this question that have been popular in philosophy: The isomorphism ap-proach, the functional role approach and the informational approach. All threeappear in the philosophy of neuroscience.Proponents of the isomorphism approach construe representation as a rela-tion of resemblance that obtains between representations and that which theyrepresent. Such resemblances are often thought to be abstract or second-orderresemblance, meaning, for instance even though a representation and what itrepresents might not have a first-order resemblance of being, e.g., the samecolour, they may still enter into systems of relationships such that the relation-ships may be mapped onto one another (as in the mapping of various heightsof a mercury column in a thermometer onto various temperatures). (See, forinstance, Churchland 2007; Mandik et. al 2007; O’Brien/Opie 2004).Proponents of functional role semantics propose that the content of a rep-resentation, what it is about, is determined by the functional/causal relationsit enters into with other representations (Block 1986). For informational ap-proaches, a representation has content, is about something, in virtue of certainkinds of causal interactions with what it represents (Dretske 1981, 1988). Inphilosophy of neuroscience, Paul Churchland has subscribed to a functional rolesemantics at least since 1979. His account is further fleshed out in terms ofstate-space semantics (P. M. Churchland 1989; 1995). However, certain as-pects of Churchland’s 1979 account of intentionality also mirror informationalapproaches.The neurobiological paradigm for informational semantics is the feature de-tector, for example, the device in a frog that allows it to detect flies. Lettvinet al. (1959) identified cells in the frog retina that responded maximally tosmall shapes moving across the visual field. Establishing that something hasthe function of detecting something is difficult. Mere covariation is often insuf-ficient. Hubel and Wiesel (1962) identified receptive fields of neurons in striatecortex that are sensitive to edges. Did they discover edge detectors? Lehky andSejnowski (1988) challenge the idea that they had, showing that neurons withsimilar receptive fields emerge in connectionist models of shape-from-shadingnetworks. (See P. S. Churchland/Sejnowski 1992 for a review.) Akins (1996)The Philosophy and Neuroscience Movement 395offers a different challenge to informational semantics and the feature detectionview of sensory function through a careful analysis of thermoperception. Sheargues that such systems are not representational at all.One issue of considerable interest is how the brain does time. How the braindoes objective time, actual persistence, is interesting enough but even moreinteresting is the subjective time of behaviour: the temporal representation thatis analogous to egocentric space (in contrast to objective or allocentric space).How can times be represented in the brain so that when we recall them, we recallthem as falling into a temporal order. How, for example, when we recall a seriesof sounds that we have heard, do we hear it as a melody rather than as a chord?As was true of neural syntax, any worked-out story about the architecture ofneural representation will hold implications for neural semantics, for the questionof how neural representations can come to have content, meaning, be about statesof affairs beyond themselves.5.4 Visuomotor TransformationA specific but absolutely central topic to do with neural representation is vi-suomotor transformation, that is to say, how we use visual information to guidemotor control.Here the leading theory, due to Milner and Goodale (1995), is that we havetwo complementary visual systems, vision-for-perception and vision-for-action.They base their conclusion on a double dissociation between two kinds of disorderfound in brain-lesioned human patients: visual form agnosia and optic ataxia.Milner and Goodale claim that this functional distinction mirrors the anatomicaldistinction between the ventral pathway (to the side and near the bottom of thebrain) and the dorsal pathway (to the rear and near the top of the brain) in thevisual system of primates. Probably no other claim in cognitive neurosciencehas attracted as much attention as this one in the past ten or twelve years.Another important body of work in visuomotor control focuses on the ideathat spatial perception and motor output are interdependent. There are twobroad approaches. One posits mental representations mediating between per-ception and action. This approach is often called representationalism. Theother approach, a kind of antirepresentationalism, opposes this idea, arguingthat intelligent, visually guided behaviour can be explained without positing in-termediaries with representational or semantic properties between sensory inputand motor output.5.5 Colour VisionThe final two issues on which we will focus in this quick survey of issues cur-rently at the interface between philosophy and neuroscience are colour visionand consciousness. Any complete theory of neural representation would have tocontain a theory of both.396 Andrew Brook/Pete MandikThe biggest issue to do with colour vision, as we said, is the issue of howto think about the relationship of colour experience to the causal factors thatproduce colour experience. For example, experiences of different colours are theresult of combinations of intensities of light of the three broad wavelengths oflight to which the retina is sensitive (four wavelengths in some women) plus otherfactors. Light of three intensities at three wavelengths is nothing like redness asone experiences it. So how should we think of the relationship between the two?Even worse, some argue that colour experience arises from processing thatdistorts the stimulus features that are its main causes, thereby largely construct-ing a world of perceived colour that has almost nothing to do with how the worldactually is. For these people, perceived colour similarity is a systematic misrep-resentation of the corresponding stimuli. How such systematic misrepresentationcould have come to have a survival or reproductive advantage is just one of thepuzzling, even baﬄing questions to which contemporary work in neuroscienceon colour gives rise.Most remarkably of all, we can have colour experiences that represent physi-cally impossible colours. In a stunning example of neurophilosophy at work, PaulChurchland (2005) has shown that by exploiting shifts in experienced colour dueto tiredness and habituation, experiences of colour can be brought about wherethe colours could not exist on standard colour wheels and other theories of thestructure of colour and, moreover, would require physically-impossible states, forexample, that things in one’s world be emitting light and be emitting no lightat the same time. Indeed, as Churchland shows, some of the colour experiencesthat we can have cannot even be represented by a colour sample.6. ConsciousnessMost of the philosophical interest in consciousness starts from the question ofwhether consciousness could possibly be a physical process of any kind, let alonea brain process. A common view in philosophy of neuroscience is that everythingto do with the mind, including consciousness, will turn out to be explicable interms of neurophysiology—not even explanatory autonomy is allowed. If con-sciousness is not something that neuroscience can capture, then that hallowedshibboleth of neuroscience will be false and there will be at least severe limita-tions on the extent to which there could ever be a science of consciousness.In the face of claims that at least something about consciousness is not neuralor even physical at all, cognitive neuroscientists and their philosopher fellow-travellers have tended to one or the other of three different kinds of reaction:1. They try to show that the claim is wrong (or incoherent, or in some otherway epistemically troubled) (Dennett 1991; 1995; Tye 1993; Brook/Raymont,forthcoming). Or,2. They just ignore the claim. This is the approach taken by many cognitiveand neuro-scientists. Or,3. They throw science at it and attempt implicitly or explicitly to produce theThe Philosophy and Neuroscience Movement 397kind of account that is supposed to be impossible (Dennett 1978; Hardin1988; Clark 1993; Akins 1993a; 1993b; 1996; Hardcastle 1997; Baars 1988;Rosenthal 1991; Mandik, in press).The usual way to argue the main idea in (1), that there is nothing unique orsui generis about consciousness, is to tackle the arguments that claim that thereis and try to show that they do not work. Here is a sample of such arguments.Nagel (1974) argued that because conscious experience is subjective, i.e., directlyaccessible by only the person who has it, we are barred from ever understandingit fully, including whether and if so how it could be physical. For example, even ifwe knew all there is to know about bat brains, we would not know what it is liketo be a bat because bat conscious experience would be so different from humanconscious experience. Later, Jackson (1986), McGinn (1991), Chalmers (1996),and others extended this line of thought with zombie thought experiments andthought experiments about colour scientists who have never experienced colour.Zombie thought experiments are representative of the genre. Consider whatphilosophers call qualia: the introspectible aspects of conscious experiences,what it is like to be conscious of something. Those who hold that consciousnessis something unique argue that there could be beings who are behaviourally,cognitively, and even physically exactly like us, yet they have no conscious ex-perience at all. If so, conscious experience cannot be a matter of behaviour,cognition, or physical makeup.A variant, inverted spectrum thought experiments, urge that others couldhave radically different conscious experience of, in this case, colour with nochange in behaviour, cognition, or physical makeup. For example, they might seegreen where we see red (inverted spectrum) but, because of their training, etc.,they use colour words, react to coloured objects, and even process informationabout colour exactly as we do. If inverted spectra are possible, then the sameconclusion follows as from the alleged possibility of zombies: consciousness isnot safe for neuroscience.Zombie and inverted spectra arguments strive to show that representationscan have functionality as representations without consciousness. A more sci-entific way to argue for a similar conclusion involves appeal to cases of blindsight and inattentional blindness. Due to damage to the visual cortex, blind-sight patients have a scotoma, a ‘blind spot’, in part of their visual field. Askthem what they are seeing there and they will say, “Nothing”. However, if youask them instead to guess what is there, they guess with far better than chanceaccuracy. If you ask them to reach out to touch whatever might be there, theyreach out with their hands turned in the right way and fingers and thumb atthe right distance apart to grasp anything that happens to be there. And so on(Weiskrantz 1986).Inattentional blindness and related phenomena come in many different forms.In one form, a subject fixates (concentrates) on a point and is asked to note somefeature of an object introduced on or within a few degrees of fixation. After afew trials, a second object is introduced, in the same region but usually not inexactly the same place. Subjects are not told that a second object will appear.398 Andrew Brook/Pete MandikWhen the appearance of the two objects is followed by 1.5 seconds of masking,at least one-quarter of the subjects and sometimes almost all subjects have noawareness of having seen the second object.2There is a sense in which the inattentionally blind are not conscious of whatthey missed: they did not notice and cannot report on the item(s). However,it can be argued that in another sense, they are conscious of the things onwhich they cannot report. For example, their access to the missed items isextensive, much more extensive than the access that blindsight patients haveto items represented in their scotoma. When the second object is a word, forexample, subjects clearly encode it and process its meaning. Evidence? Whenasked shortly after to do, for example, a stem completion task (i.e., to completea word of which they have been given the first syllable or so), they complete theword in line with the word they claim not to have seen much more frequentlythan controls do. Thus, subjects’ access to words that they miss involves theprocessing of semantic information. If so, their access to the missed words ismuch like our access to items in our world when we are conscious of them.Thus, an alternative account of the ‘blindness’ in these cases is that subjectsare conscious of what they cannot report but are not conscious of being thusconscious (so they cannot report it). If so, far from inattentional blindnesssuggesting that representations can have full functionality without consciousness,the phenomenon would pull in the opposite direction. At minimum, it seems tobe at least fully compatible with the idea that consciousness is a form of cognition(see Mandik 2005).So what about philosophers and neuroscientists who ignore that challengingclaim that consciousness is unique, sui generis, or throw science at it? Theirnumbers are legion and we won’t attempt to examine the various alternativetheories here. They range from attention theories to global work space theo-ries to pandemonium architecture models to connectionist and dynamic systemsmodels. Recent neuroscience has made a lot of progress in identifying the regionsand systems in the brain most closely associated with consciousness of variouskinds (Koch 2004 gives an excellent summary). What is important here is thatnearly all this work starts from a common assumption, that consciousness is afairly standard cognitive phenomenon that can be captured in the kind of theorythat captures cognitive functioning in general, without any attempt to argue forthe assumption.Ignoring the challenging claim is risky (not to mention a bit rude). It risksleaving many—and not just dyed-in-the-wool anticognitivists—feeling that thereal thing, consciousness itself, has been left out, that the researcher has covertlychanged the subject and is talking about something else. This is how manyreact to suggestions that consciousness is, for example, synchronized firing ofneurons. “Surely”, they react, “you could have the synchronized firing withoutconsciousness. If so, consciousness is not synchronized firing of neurons. Maybethis firing pattern is a neural correlate of consciousness (NCC), but it is notwhat consciousness is”.2For more on this fascinating group of phenomena, see Mack, http://psyche.cs.monash.edu.au/v7/psyche-7-16-mack.html or Mack/Rock 1998.The Philosophy and Neuroscience Movement 399Throwing science at the challenge faces exactly the same risk. No matterwhat the scientific model, sceptics about a science of consciousness can alwaysclaim that the model is not a model of consciousness, that the researcher haschanged the topic to something that can be understood neuroscientifically, ismerely talking about correlates of consciousness (NCCs) or whatever. More-over, it would appear that no amount of neuroscience could make this objectionirrational. No matter what the scientific model of consciousness, the charge canalways be levelled that the model is studying mere correlates, that it is not un-covering the nature of consciousness. Many now believe that the only approachwith any hope of success so far as a science of consciousness is concerned is tobeard the sceptics in their lair, to tackle the arguments that they advance andshow that they just don’t work or worse, are incoherent. To make conscious-ness safe for neuroscience, we would have to show one (or both) of two things.The first would be that the sceptics have given no good reason to believe thatconsciousness is not safe for neuroscience. The second, and perhaps stronger,would be to show that consciousness is not and could not be unique in the wayrequired by sceptics. Both of these are pre-eminently philosophical tasks.In general, at the interface between neuroscience and philosophy at the mo-ment, there is a great ferment. Results in neuroscience are shedding light on,even reshaping, traditional philosophical hunches about and approaches to themind. And neuroscience is throwing up some new issues of conceptual clarifi-cation and examination of possibilities that philosophers are better equipped tohandle than anyone else. We live in interesting times!BibliographyAkins, K. (1993a), What Is It Like to be Boring and Myopic? In: B. Dahlbom (ed.),Dennett and His Critic, New York— (1993b), A Bat Without Qualities, in: M. Davies/G. Humphreys (eds.), Conscious-ness: Psychological and Philosophical Essays, New York— (1996), Of Sensory Systems and the ‘Aboutness’ of Mental States, in: Journal ofPhilosophy 93(7), 337–372Baars, D. (1988), A Cognitive Theory of Consciousness, CambridgeBechtel, W./R.C.Richardson (1993), Discovering Complexity: Decomposition and Lo-calization as Scientific Research Strategies, Princeton/NJ—/J. Mundale (1997), Multiple Realizability Revisited: Linking Cognitive and NeuralStates, in: Philosophy of Science 66, 175–207—/A. Abrahamsen (2002), Connectionism and the Mind: Parallel Processing, Dy-namics, and Evolution in Networks, Oxford—/G. Graham (1998), The Life of Cognitive Science, in: W. Bechtel/G. Graham(eds.), A Companion to Cognitive Science. Oxford, 1–104—/P. Mandik/J. Mundale/R. Stuﬄebeam (eds.) (2001), Philosophy and the Neuro-sciences: A Reader, Oxford— (2007), Mental Mechanisms, LondonBickle, J. (1998), Psychoneural Reduction: The New Wave, Cambridge/MA— (in press) (ed.) The Oxford Handbook of Philosophy and Neuroscience, OxfordBiro, J. (1991), Consciousness and Subjectivity in Consciousness, in: E. Villaneuva400 Andrew Brook/Pete Mandik(ed.), Philosophical Issues, Atascadero/CABlock, N. (1986), Advertisement for a Semantics for Psychology, in: French, P.A.(ed.), Midwest Studies in Philosophy, 615—678Bliss, T.V. P./T. Lomo (1973), Long-Lasting Potentiation of Synaptic Transmissionin the Dentate Area of the Anaesthetized Rabbit Following Stimulation of ThePerforant Path, in: Journal of Physiology (London) 232, 331–356Bower, J./D. Beeman (1995), The Book of GENESIS, New YorkBrentano, F. (1874), Psychology from an Empirical Standpoint. A. C. Pancurello/ D.B. Tyrrell/L. L. McAlister, trans., New YorkBrook, A./K. Akins (eds.) (2005), Cognition and the Brain: The Philosophy and Neu-roscience Movement, New York— /R. Stainton] (2000), Knowledge and Mind, Cambridge/MA— /P. Raymont] (forthcoming), A Unified Theory of Consciousness, Cambridge/MACaplan, D./T. Carr/J. Gould/R. Martin (1999), Language and Communication, in:Zigmond et al. 1999Chalmers, D. (1996), The Conscious Mind, OxfordChurchland, P.M. (1979), Scientific Realism and the Plasticity of Mind, Cambridge— (1981), Eliminative Materialism and the Propositional Attitudes, in: Journal ofPhilosophy 78, 67–90— (1989), A Neurocomputational Perspective: The Nature of Mind and the Structureof Science, Cambridge/MA— (1993), Sensory Qualities, Cambridge— (1995), The Engine of Reason, The Seat of the Soul , Cambridge/MA— (2005), Chimerical Colours, in: Brook, A./K. Akins (eds.) (2005)— (2007), Neurophilosophy at Work, CambridgeChurchland, P. S. (1986) Neurophilosophy, Cambridge/MA—/T. Sejnowski (1992), The Computational Brain, Cambridge/MAClark, A. (1993), Associative Engines, Cambridge/MACraver, C. (2007), Explaining the Brain, OxfordDennett, D.C. (1978), Why You Can’t Make a Computer That Feels Pain, in: Syn-these 38, 415–449— (1991), Consciousness Explained, New York— (1995), The Path Not Taken, in: Behavioral and Brain Sciences 18 (2), 252–253Descartes R. (1649), Les passions de l’âme, Amsterdam, in : Adam, C./P. Tannery,Œuvres de Descarte, Paris, 1964–74, vol. XI..Dretske, F. (1981), Knowledge and the Flow of Information, Cambridge/MA— (1988) Explaining Behavior, Cambridge/MAFeigl, H. (1958/1967), The ‘Mental’ and the ‘Physical’. The Essay and a Postscript,MinneapolisFodor, J. A. (1974), Special Sciences (or: The Disunity of Science as a Working Hy-pothesis), in: Synthese 28, 97–115— (1983), The Modularity of Mind, Cambridge/MAGold, I./D. Stoljar (1999), A Neuron Doctrine in the Philosophy of Neuroscience, in:Behavioral and Brain Sciences 22 (5), 809–830Grush, R. (1998), Skill and Spatial Content, in: Electronic Journal of Analytic Phi-losophy 6(6), http://ejap.louisiana.edu/EJAP/1998/grusharticle98.html— (2001), The Semantic Challenge to Computational Neuroscience, in: P. Machamer/R.Grush/P. McLaughlin (eds.) (2001), Theory and Method in the Neurosciences,Pittsburgh/PA— (2002), Cognitive Science, in: P. Machamer/M. Silberstein (eds.). Guide to Phi-The Philosophy and Neuroscience Movement 401losophy of Science, OxfordHardcastle, V.G. (1997), When a Pain Is Not, in: Journal of Philosophy 94(8), 381–406Hardin, C. L. (1988), Colour for Philosophers, Indianapolis/IDHebb, D. (1949), The Organization of Behavior, New YorkHooker, C. (1981), Towards a General Theory of Reduction. Part I: Historical andScientific Setting. Part II: Identity in Reduction. Part III: Cross-Categorial Re-duction, in: Dialogue 20, 38–59Hubel, D./T. Wiesel (1962), Receptive Fields, Binocular Interaction and FunctionalArchitecture In the Cat’s Visual Cortex, in: Journal of Physiology (London) 195,215–243Jackson, F. (1986), What Mary didn’t Know, in: Journal of Philosophy 83(5), 291–295Kandel, E. (1976), Cellular Basis of Behavior, San FranciscoKeeley, Brian (ed.) (2006), Paul M. Churchland (Contemporary Philosophy in Focus),CambridgeKoch, C. (2004), Quest for Consciousness, Englewood/COLehky, S.R./T. Sejnowski (1988), Network Model of Shape-from-Shading: Neural Func-tion Arises from Both Receptive and Projective Fields, in: Nature 333, 452-454Lettvin, J.Y./H.R. Maturana/W. S. MCulloch/W.H. Pitts (1959), What the Frog’sEye Tells the Frog’s Brain, in: Proceedings of the IRF 47 (11), 1940–1951Machamer, P./L. Darden/C. Craver (2000), Thinking about Mechanisms, in: Philos-ophy of Science 67, 1–25Mack, A. (?????), Inattentional Blindness,http://psyche.cs.monash.edu.au/v7/psyche-7-16-mack.htm—/I. Rock (1998), Inattentional Blindness, Cambridge/MAMandik, P. (2001), Mental Representation and the Subjectivity of Consciousness, in:Philosophical Psychology 14 (2), 179–202— (2005), Phenomenal Consciousness and the Allocentric-Egocentric Interface, in: R.Buccheri et al. (eds.), Endophysics, Time, Quantum and the Subjective World,???????????????— (2006), The Instrospectibility of Brain States as Such, in: Keeley 2006— (in press), The Neurophilosophy of Subjectivity, in: J. Bickle (ed.), The OxfordHandbook of Philosophy and Neuroscience, Oxford—/W. Bechtel (2002), Philosophy of Science, in: L. Nadel (ed.), The Encyclopaediaof Cognitive Science, London—/M.Collins/A.Vereschagin (2007), Evolving Artificial Minds and Brains, in: A.Schalley/D. Khlentzos (eds.), Mental States, Vol. 1: Nature, Function, Evolution,AmsterdamMcCauley, R. (2001), Explanatory Pluralism and the Co-evolution of Theories of Sci-ence, in: W. Bechtel/P. Mandik/J. Mundale/R. S. Stuﬄebeam (eds.), Philosophyand the Neurosciences: A Reade, OxfordMcGinn, C. (1991), The Problem of Consciousness: Essays Towards a Resolution,OxfordMilner, A.D./M.A. Goodale (1995), The Visual Brain in Action, OxfordMundale, J./W. Bechtel| (1996), Integrating Neuroscience, Psychology, and Evolu-tionary Biology through a Teleological Conception of Function, in: Minds andMachines 6, 481–505Nagel, T. (1971), Brain Bisection and the Unity of Consciousness, in: Synthese 22,396-413402 Andrew Brook/Pete MandikNewell, A. (1980), Physical Symbol Systems, in: Cognitive Science 4, 135–183O’Brien, G./J. Opie (2004), Notes Toward a Structuralist Theory of Mental Repre-sentation, in: H.Clapin/P.Staines/P.Slezak (eds.), Representation in Mind: NewApproaches to Mental Representation, AmsterdamPlace, U.T. (1956), Is Consciousness a Brain Process? In: The British Journal ofPsychology 47(1), 44–50Putnam, H. (1967), Psychological Predicates, in: W. H. Capitan/D. D. Merrill (eds.),Art, Mind and Religion, PittsburghRosenthal, D. (1991), The Nature of Mind, OxfordSmart, J. J. C. (1959), Sensations and Brain Processes, in: Philosophical Review 68,141–156Stich, S. (1983), From Folk Psychology to Cognitive Scienc, Cambridge/MAStuﬄebeam, R./W.Bechtel (1997), PET: Exploring the Myth and the Method, in:Philosophy of Science (Supplement) 64(4,: S95–S106Tye, M. (1993), Blindsight, the Absent Qualia Hypothesis, and the Mystery of Con-sciousness, in: C. Hookway (ed.), Philosophy and the Cognitive Sciences, Cam-bridgevan Gelder, T. (1998), Mind as Motion: Explorations in the Dynamics of Cognition,in: Journal of Consciousness Studies 5(3), 381–383von Eckardt Klein, B. (1975), Some Consequences of Knowing Everything (Essential)There is to Know About one’s Mental States, in: Review of Metaphysics 29, 3–18— (1978), Inferring Functional Localization from Neurological Evidence, in: E. Walker(ed.), Explorations in the Biology of Language, Cambridge/MAWeiskrantz, L. (1986), Blindsight: A Case Study and Implication, OxfordZigmond, M./F.Bloom/S. Landis/J.Roberts/L. Squire (eds.) (1999), Fundamental Neu-roscience, San Diego